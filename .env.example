# ========================================
# ACTIVE RECALL SYSTEM CONFIGURATION
# ========================================
# Copy this file to .env and add your actual API keys
# NEVER commit the .env file to git - it contains sensitive information

# ========================================
# BATCH SERVICE CONFIGURATION
# ========================================
# Character count threshold before auto-flushing batches to LLM
# If not set, will use provider/model-specific defaults
BATCH_FLUSH_THRESHOLD=60000

# ========================================
# LLM PROVIDER SELECTION
# ========================================
# Choose your LLM provider: openai | gemini | anthropic
LLM_PROVIDER=gemini

# ========================================
# GOOGLE GEMINI CONFIGURATION
# ========================================
# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# Model Selection:
# - flash-lite (most cost-effective: $0.10/$0.40 per 1M tokens)
# - flash (balanced: $0.30/$1.20 per 1M tokens) 
# - pro-experimental (most capable: $7.00/$21.00 per 1M tokens)
# - flash-thinking (with reasoning: $0.50/$2.00 per 1M tokens)
GEMINI_MODEL=flash-lite

# Optional: Google Cloud Project (for Vertex AI)
# GEMINI_PROJECT_ID=your-gcp-project-id
# GEMINI_LOCATION=us-central1

# Model-Specific Character Thresholds (override BATCH_FLUSH_THRESHOLD)
GEMINI_FLASH_LITE_THRESHOLD=40000
GEMINI_FLASH_THRESHOLD=60000
GEMINI_PRO_EXPERIMENTAL_THRESHOLD=100000
GEMINI_FLASH_THINKING_THRESHOLD=80000

# Generation Configuration
GEMINI_MAX_TOKENS=200
GEMINI_TEMPERATURE=0.1
GEMINI_TOP_K=40
GEMINI_TOP_P=0.95

# Performance & Reliability
GEMINI_REQUEST_TIMEOUT=30000
GEMINI_RETRY_ATTEMPTS=3
GEMINI_RETRY_DELAY=1000

# Multi-Concept Extraction Settings
GEMINI_MULTI_CONCEPT_ENABLED=true
GEMINI_MAX_CONCEPTS_PER_DISTILLATION=5
GEMINI_SPECIFICITY_ENFORCEMENT=true

# Rate Limiting
GEMINI_DAILY_REQUEST_LIMIT=10000
GEMINI_BURST_LIMIT=10
GEMINI_QUOTA_WARNING_THRESHOLD=0.8

# Advanced Prompting Features
GEMINI_CHAIN_OF_THOUGHT_ENABLED=true
GEMINI_FEW_SHOT_EXAMPLES_ENABLED=true
GEMINI_OCR_AWARENESS_ENABLED=true

# Content Filtering
GEMINI_EDUCATIONAL_CONTENT_FILTER=true
GEMINI_COMMERCIAL_CONTENT_FILTER=true
GEMINI_MIN_CONTENT_LENGTH=10
GEMINI_MAX_CONTENT_LENGTH=50000

# Safety Settings
GEMINI_HARM_BLOCK_THRESHOLD=BLOCK_MEDIUM
# GEMINI_SAFETY_CATEGORIES=harassment,hate_speech,sexually_explicit,dangerous_content

# Fallback Behavior
GEMINI_FALLBACK_ENABLED=true
GEMINI_FALLBACK_STRATEGY=simple

# Debugging & Monitoring
GEMINI_DEBUG_MODE=false
GEMINI_LOG_LEVEL=info
GEMINI_METRICS_ENABLED=false

# ========================================
# OPENAI CONFIGURATION (LEGACY)
# ========================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# Model Selection: gpt-3.5-turbo | gpt-4 | gpt-4o | gpt-4o-mini
OPENAI_MODEL=gpt-3.5-turbo

# Model-Specific Character Thresholds
OPENAI_GPT_3_5_TURBO_THRESHOLD=10000
OPENAI_GPT_4_THRESHOLD=80000
OPENAI_GPT_4O_THRESHOLD=80000
OPENAI_GPT_4O_MINI_THRESHOLD=40000

# Generation Configuration
OPENAI_MAX_TOKENS=200
OPENAI_TEMPERATURE=0.1

# Performance Settings
OPENAI_REQUEST_TIMEOUT=30000
OPENAI_RETRY_ATTEMPTS=3
OPENAI_RETRY_DELAY=1000

# Multi-Concept Settings
OPENAI_MULTI_CONCEPT_ENABLED=true
OPENAI_MAX_CONCEPTS_PER_DISTILLATION=5
OPENAI_SPECIFICITY_ENFORCEMENT=true

# Rate Limiting
OPENAI_DAILY_REQUEST_LIMIT=1000
OPENAI_QUOTA_WARNING_THRESHOLD=0.8

# Advanced Prompting
OPENAI_CHAIN_OF_THOUGHT_ENABLED=true
OPENAI_FEW_SHOT_EXAMPLES_ENABLED=true
OPENAI_OCR_AWARENESS_ENABLED=true

# Content Filtering
OPENAI_EDUCATIONAL_CONTENT_FILTER=true
OPENAI_MIN_CONTENT_LENGTH=10
OPENAI_MAX_CONTENT_LENGTH=50000

# Fallback & Monitoring
OPENAI_FALLBACK_ENABLED=true
OPENAI_DEBUG_MODE=false
OPENAI_LOG_LEVEL=info

# ========================================
# CACHING CONFIGURATION
# ========================================
# Enable caching to reduce API costs and improve performance
CACHE_ENABLED=true

# ========================================
# DEVELOPMENT SETTINGS
# ========================================
# Log level: error | warn | info | debug
LOG_LEVEL=info

# Enable detailed logging for development
DEBUG_MODE=false

# ========================================
# COST OPTIMIZATION RECOMMENDATIONS
# ========================================
# For high-volume processing: Use Gemini Flash-Lite
# For balanced performance: Use Gemini Flash  
# For complex reasoning: Use Gemini Pro Experimental
# For cost-sensitive applications: Enable caching and use higher thresholds

# ========================================
# ADVANCED PIPELINE CONFIGURATION
# ========================================
# Routing Thresholds (0.0-1.0 similarity scores)
HIGH_CONFIDENCE_THRESHOLD=0.90          # Score above which content is automatically routed to existing folder
LOW_CONFIDENCE_THRESHOLD=0.75           # Score below which content is considered for new folder creation
NEW_TOPIC_THRESHOLD=0.60               # Minimum score to suggest creating a new topic folder
DUPLICATE_THRESHOLD=0.95               # Score above which content is considered a duplicate
FOLDER_PLACEMENT_THRESHOLD=0.80        # Minimum score for placing content in a specific folder

# Batch Processing
MIN_CLUSTER_SIZE=5                      # Minimum number of items required to form a cluster
ENABLE_BATCH_CLUSTERING=true            # Group related content together for better organization
ENABLE_FOLDER_CREATION=true             # Allow automatic creation of new study folders

# Text Validation
MIN_TEXT_LENGTH=10                      # Reject content shorter than this (characters)
MAX_TEXT_LENGTH=10000                   # Reject content longer than this (characters)

# Vector Configuration (for semantic similarity)
VECTOR_DIMENSIONS=384                   # Size of embedding vectors (must match model output)
MAX_FOLDER_MEMBERS=1000                 # Maximum concepts per folder before splitting
MAX_EXEMPLARS=50                        # Maximum representative examples per folder
CONTEXT_SEARCH_LIMIT=50                 # How many similar items to consider for context
TITLE_SEARCH_LIMIT=20                   # How many items to search when generating folder titles

# Folder Scoring Weights (must sum to ~1.0)
AVG_SIMILARITY_WEIGHT=0.5               # Weight for average similarity to folder contents
MAX_SIMILARITY_WEIGHT=0.3               # Weight for maximum similarity to any item in folder
MAX_COUNT_BONUS=0.2                     # Maximum bonus for folders with more items
COUNT_BONUS_MULTIPLIER=1.5              # Multiplier for count-based scoring bonus

# Clustering Configuration
CLUSTER_SIMILARITY_THRESHOLD=0.75       # Minimum similarity to group items together
MIN_CLUSTER_FOR_SUGGESTION=3            # Minimum cluster size to suggest as new folder
UNSORTED_SIMILARITY_THRESHOLD=0.70      # Threshold for matching against unsorted items
UNSORTED_SEARCH_LIMIT=25                # Maximum unsorted items to search

# Cache Configuration
CACHE_TTL_DAYS=30                       # How long to keep cached results (days)
ENABLE_CACHING=true                     # Enable caching to improve performance and reduce API costs

# ========================================
# APPLICATION POLLING CONFIGURATION
# ========================================
# Window monitoring intervals (milliseconds)
WINDOW_POLL_MS=1000                     # How often to check for active window changes
STUDYING_OCR_POLL_MS=30000              # How often to capture screen content when studying (30 seconds)
IDLE_REVALIDATION_THRESHOLD_MS=900000   # When to recheck if user is still studying (15 minutes)
IDLE_REVALIDATION_INTERVAL_MS=60000     # How often to check for user activity when idle (1 minute)
WINDOW_CACHE_TTL=900000                 # How long to remember window classification (15 minutes)
NEW_WINDOW_PIPELINE_DELAY_MS=15000      # Wait time before processing new window content (15 seconds)

# ========================================
# IDLE FLUSH CONFIGURATION
# ========================================
# Batch idle flush timeout (milliseconds)
BATCH_IDLE_FLUSH_TIMEOUT_MS=300000      # Auto-flush accumulated batches after being idle for 5 minutes

# ========================================
# ML MODEL CONFIGURATION
# ========================================
# Use full-size models vs lite models (impacts performance/accuracy trade-off)
USE_FULL_MODELS=false                   # true=better accuracy but slower, false=faster but less accurate

# Segmented classification threshold (0.0-1.0)
SEGMENT_THRESHOLD_PROPORTION=0.5        # Confidence threshold for classifying content segments

# ========================================
# ADDITIONAL DISTILLATION SETTINGS
# ========================================
# Legacy OpenAI settings for compatibility
MAX_CONCEPTS_PER_DISTILLATION=5
REQUEST_TIMEOUT=30000
RETRY_ATTEMPTS=3
RETRY_DELAY=1000
DAILY_REQUEST_LIMIT=1000
BURST_LIMIT=10
QUOTA_WARNING_THRESHOLD=0.8
PROMPT_VERSION=v2.0-specificity
CHAIN_OF_THOUGHT_ENABLED=true
FEW_SHOT_EXAMPLES_ENABLED=true
OCR_AWARENESS_ENABLED=true
EDUCATIONAL_CONTENT_FILTER=true
COMMERCIAL_CONTENT_FILTER=true
MIN_CONTENT_LENGTH=10
MAX_CONTENT_LENGTH=50000
FALLBACK_ENABLED=true
FALLBACK_STRATEGY=simple
MULTI_CONCEPT_ENABLED=true
SPECIFICITY_ENFORCEMENT=true
METRICS_ENABLED=false

# ========================================
# ENVIRONMENT CONFIGURATION
# ========================================
# Node.js environment: development | production | test
NODE_ENV=development