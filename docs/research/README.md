# Research Documentation

## Classification Research and Analysis

###  Documents in this folder:

- **`SINGLE-LABEL-ANALYSIS.md`** - Research breakthrough: Single-label classification with confidence thresholding (85%+ accuracy vs 60% with binary approach)
- **`TOPIC-CLASSIFICATION-ANALYSIS.md`** - Comprehensive analysis of topic-based classification approaches and model comparison

###  Key Research Findings

**Single-Label Breakthrough**:
- **Problem**: Binary classification (studying vs idle) achieved only 60% accuracy
- **Solution**: Single-label confidence scoring - "How confident are you this text is about [topic]?"
- **Result**: **85%+ accuracy** improvement with topic-specific thresholds

**Model Performance Comparison**:
- **RoBERTa-Large-MNLI**: **85.4%** average accuracy (best overall)
- **DistilBERT-MNLI**: **75.0%** accuracy (resource-efficient)
- **BART-Large-MNLI**: **66.7%** accuracy (experimental)
- **DeBERTa-v3-Large**: **81.3%** accuracy (strong for complex topics)

**Topic-Specific Results**:
- **Chemistry**: **91.7%** accuracy
- **JavaScript Programming**: **91.7%** accuracy  
- **History**: **91.7%** accuracy
- **Machine Learning**: **75.0%** accuracy

###  Production Validation

**Real OCR Content Testing**:
- **Multi-paragraph textbook chapters** processed successfully
- **Research papers with equations** handled accurately
- **Programming tutorials with code** classified correctly
- **OCR artifacts** (character substitutions) don't degrade performance

**Cross-Domain Robustness**:
- **Chemistry textbooks** → 99.2% confidence
- **Programming tutorials** → 95.8% confidence  
- **ML research papers** → 90%+ confidence
- **Edge cases** (news about topics) handled appropriately